---
title: "Machine Learning Algorithm to classify barbell lifting quality"
author: "Sok PHAN, phansoks@gmail.com"
date: "Friday, August 21, 2015"
output: html_document
---

##Overview
In this project, we will use data from accelerometers on the belt, forearm, arm, 
and dumbell of 6 participants, who were asked to perform barbell lifts correctly 
(classe 'A' in data set) and incorrectly in 5 different ways (classe 'B' to 'E'). 
The data for this project come from the Groupware@LES (http://groupware.les.inf.puc-rio.br/har).

Our goal is to build a machine learning algorithm, which predicts the classe, ie. 
if the participant lifted correctly the barbell or made one of the 5 mistakes.

###Exploratory Data Analysis
```{r, message=FALSE}
training <- read.csv("pml-training.csv", na.strings=c("NA",""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA",""))
```

After loading the data, we can notice that original training set has `r dim(training)[1]` 
observations and 159 possible predictors. Doing a summary on training
set, we clearly see many variables having empty/0/NA values. We will have to handle them.

###Machine Learning Algorithm Creation
First, we need to reduced the number of predictors because it would take an great 
amount of time and to train a model based on 159 predictors. Having a look at first columns
of data set, we decided to remove them as we consider they are not relevant information.

Then, we also remove columns having less than 95% of observation filled. They correspond
to calculated data such as std, variance, kurtosis, skewness, etc for one specific performed 
activity. There are hundreds of them, so we think removing them will improve significantly
our computation time without decreasing our predictions. 

Finally, we have `r dim(training)[2] - 1` predictors in our model.

```{r, message=FALSE}
training <- subset(training, select = -c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window))
testing <- subset(testing, select = -c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window))

filled_data <- apply(!is.na(training),2,sum)/dim(training)[1] > 0.95
training<-training[,filled_data]
testing<-testing[,filled_data]
```

###Cross validation
As training method, using regressions would not have been a good idea as we want
to classify between 6 non-numeric outcomes: A, B, C, D, E. Trying differents methods
(trees, bagging, random forests and boosting ), it appears random forests ended
up with smaller error rate. We also specify the number of repetition for the 
cross validation to 5.

Due to high memory and cpu usage, we had to train our model on a partition of our 
training set. For this report, we put 33% as an example but we used a 80% partition
for testing set prediction.

```{r, eval=FALSE}
library(doParallel)
registerDoParallel(cores=2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(123)

partition <-createDataPartition(y=training$classe,p=0.33,list=FALSE)
modelFit<-train(classe~.,data=training[partition,],method="rf",
                trControl=trainControl(method="cv",number=5),
                prox=TRUE,allowParallel=TRUE, model=FALSE)
```

###Expected out of sample error
```{r, eval=FALSE}
> print(modelFit)

Random Forest 

6479 samples
  53 predictor
   5 classes: 'A', 'B', 'C', 'D', 'E' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 5183, 5183, 5182, 5184, 5184 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
   2    0.9825597  0.9779336  0.002646090  0.003347122
  27    0.9905849  0.9880888  0.002404419  0.003043996
  53    0.9884252  0.9853567  0.003854517  0.004879990

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 27. 
```

Best accuracy selected for the model is 0.9905849, which mean expected out of sample 
error is less than 1% (`r (100-99.05849)`% to be precise).

Confusion matrix below confirms this error rates. Indeed, out of the 19622 activity 
classes of the training set, 19512 were correctly predicted and 110 incorrectly 
predicted. This corresponds to a `r 110/19622*100`% error rate.

```{r, eval=FALSE}
> table(training$classe, predict(modelFit, newdata=training))

       A    B    C    D    E
  A 5579    0    0    0    1
  B   15 3758   24    0    0
  C    0   13 3407    2    0
  D    0    0   39 3177    0
  E    0    3    0   13 3591
```

##Conclusion
Using caret package and data provided by the Groupware@LES, we manage to build a 
machine learning able to correclty evaluate barbell lifting quality based on a selected 
set of `r dim(training)[2] - 1` predictors and the random forest method.

Based on the error rate less than 1% on training set, we can say this is quiet a
surprising result! On the testing set, it scored 100% correct results.
